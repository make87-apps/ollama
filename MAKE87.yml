build_kit:
  name: python3
  version: latest
provider_endpoints:
  - name: CHAT
    requester_message_type: make87_messages.text.text_plain.PlainText
    provider_message_type: make87_messages.text.text_plain.PlainText
  - name: IMG_CHAT
    requester_message_type: make87_messages.image.compressed.image_jpeg.ImageJPEG
    provider_message_type: make87_messages.text.text_plain.PlainText
config:
  values:
  - name: MODEL_NAME
    description: "The name of the ollama model to use. Options are: gemma3:1b, gemma3, gemma3:12b, gemma3:27b, qwq, deepseek-r1, deepseek-r1:671b, llama3.3, llama3.2, llama3.2:1b, llama3.2-vision, llama3.2-vision:90b, llama3.1, llama3.1:405b, phi4, phi4-mini, mistral, moondream, neural-chat, starling-lm, codellama, llama2-uncensored, llava, granite3.2"
    default: moondream
    required: true
    secret: false
port_requirements:
- name: Chat
  protocol: HTTP
  target_port: 11434
  publish_mode: Ingress
peripheral_requirements:
  - name: GPU
    peripheral_type: GPU